
from nltk.tokenize import sent_tokenize, word_tokenize

example_test = "hey, let us try to do something here today please"

print(sent_tokenize(example_test))
print(word_tokenize(example_test))
